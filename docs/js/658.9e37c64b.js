"use strict";(self["webpackChunkmiccai2023"]=self["webpackChunkmiccai2023"]||[]).push([[658],{658:function(a,e,i){i.r(e),i.d(e,{default:function(){return x}});var d=i(6768);const t=a=>((0,d.Qi)("data-v-498df29e"),a=a(),(0,d.jt)(),a),s={id:"submission"},n=t((()=>(0,d.Lk)("div",{class:"main-title"},[(0,d.Lk)("h1",null,"Call For Paper"),(0,d.Lk)("div",{class:"main-title-deco"})],-1))),l={key:0},o=t((()=>(0,d.Lk)("div",{id:"scope"},[(0,d.Lk)("h2",null,"Scope of the Workshop"),(0,d.Lk)("hr"),(0,d.Lk)("div",{class:"scope-contents"}," In the field of medical image analysis, existing AI solutions are typically designed and evaluated on specific datasets, making it challenging to transfer them to different tasks or handle datasets from diverse medical centers. However, real-world clinical practices vary across hospitals and institutions, resulting in different data modalities and task formulations. As a result, there is increasing attention toward developing a general model that can effectively handle various medical scenarios. Such a model, with excellent generalization ability to process different medical image modalities and perform a variety of medical AI tasks, is commonly referred to as a general medical AI. Inspired by recent advances in the generalization power of large-scale vision-language and foundation models in computer vision, this first workshop on foundation models for general medical AI (MedAGI) is dedicated to addressing the current medical AI systems and discussing opportunities for generalizing learning systems across multiple unseen tasks and domains specifically targeting various medical data (e.g., images, omics, clinical data) processing and analysis scenarios. ")],-1))),r=[o],c={key:1},v=t((()=>(0,d.Lk)("div",{id:"scope"},[(0,d.Lk)("h2",null,"Scope of the Workshop"),(0,d.Lk)("hr"),(0,d.Lk)("div",{class:"scope-contents"}," Medical image analysis has traditionally relied on AI models trained on specific datasets, which often becomes challenging when transferred to data from different medical centers. This inherent limitation has inspired a growing interest in general medical AI, capable of seamlessly adapting to various medical scenarios, data modalities, and task formulations prevalent across hospitals and institutions. Drawing parallels from the computer vision and natural language processing domains, foundation models, such as large language and vision-language models like GPT, LLaMA, stand out as quintessential general AI solutions. These models have demonstrated remarkable proficiency in a myriad of tasks owing to their massive training datasets and substantial model sizes. Yet, the translation of these successes to medical, namely the general medical AI, remains nascent. This workshop is designed to continue the success of our last yearâ€™s event and serve as a confluence of insights from the current landscape of medical AI and foundation models. This year, we aim to foster discussions that will pave the way for the evolution of task-specific medical AI systems into more generalized frameworks capable of tackling a diverse range of tasks, datasets, and domains. ")],-1))),u=[v],f={key:2},m=(0,d.Fv)('<div id="topics" data-v-498df29e><h2 data-v-498df29e>Topics</h2><hr data-v-498df29e><div id="topic-description" data-v-498df29e> Topics are included but not limited to: </div><ul id="topic-list" data-v-498df29e><li data-v-498df29e>AGI, Foundation models, and multi-purpose models for medical data</li><li data-v-498df29e>Benchmarks for general medical AI</li><li data-v-498df29e>Zero/few-shot, self-/weak-supervised learning</li><li data-v-498df29e>Domain generalization and adaptation</li><li data-v-498df29e>Pre-training, fine-tuning, prompt tuning</li><li data-v-498df29e>Open-vocabulary object detection, segmentation</li><li data-v-498df29e>Multitask learning, knowledge distillation, pseudo labeling</li><li data-v-498df29e>Current challenges and/or future trends in general medical AI</li><li data-v-498df29e>Social impact and/or ethical issues of general medical AI</li></ul></div>',1),h=[m],p={key:3},g=(0,d.Fv)('<div id="topics" data-v-498df29e><h2 data-v-498df29e>Topics</h2><hr data-v-498df29e><div id="topic-description" data-v-498df29e> Topics are included but not limited to: </div><ul id="topic-list" data-v-498df29e><li data-v-498df29e>Medical foundation models</li><li data-v-498df29e>Medical large vision-language models</li><li data-v-498df29e>Instruction tuning for medical applications</li><li data-v-498df29e>Medical multi agents and AI orchestration</li><li data-v-498df29e>Agentic reasoning for medical data</li><li data-v-498df29e>Benchmarking and evaluations for medical foundation models</li><li data-v-498df29e>Current challenges and future trends in medical foundation models</li><li data-v-498df29e>Social impact and ethical considerations in medical foundation models</li></ul></div>',1),k=[g],y=t((()=>(0,d.Lk)("h2",null,"Important Dates",-1))),w=t((()=>(0,d.Lk)("hr",null,null,-1))),L={key:4},b=(0,d.Fv)('<div id="important-dates" data-v-498df29e><div id="dates-table" data-v-498df29e><div class="date-row" data-v-498df29e><div class="dates" data-v-498df29e><span class="canceled-date" data-v-498df29e>June 25, 2023 (23:59 PDT)</span><br data-v-498df29e>July 5, 2023 (23:59PDT)</div><div class="due-work" data-v-498df29e>Paper submission due</div></div><div class="date-row" data-v-498df29e><div class="dates" data-v-498df29e><span class="canceled-date" data-v-498df29e>July 30, 2023</span><br data-v-498df29e>August 6, 2023</div><div class="due-work" data-v-498df29e>Notification of paper decisions</div></div><div class="date-row" data-v-498df29e><div class="dates" data-v-498df29e><span class="canceled-date" data-v-498df29e>August 13, 2023</span><br data-v-498df29e>August 20, 2023</div><div class="due-work" data-v-498df29e>Camera ready papers due</div></div><div class="date-row" data-v-498df29e><div class="dates" data-v-498df29e>September 6, 2023</div><div class="due-work" data-v-498df29e>Workshop proceedings due</div></div><div class="date-row" data-v-498df29e><div class="dates" data-v-498df29e>October 12, 2023</div><div class="due-work" data-v-498df29e>Workshop date</div></div></div></div>',1),A=[b],I={key:5},C=t((()=>(0,d.Lk)("div",{id:"important-dates"},[(0,d.Lk)("h2",null,"TBD")],-1))),T=[C],D={id:"instructions"},S=t((()=>(0,d.Lk)("h2",null,"Submission Instructions",-1))),E=t((()=>(0,d.Lk)("hr",null,null,-1))),M=t((()=>(0,d.Lk)("h2",null,"TBD",-1))),X=t((()=>(0,d.Lk)("div",{id:"awards"},[(0,d.Lk)("h2",null,"Awards"),(0,d.Lk)("hr"),(0,d.Lk)("h2",null,"TBD")],-1))),Y={key:0},z=t((()=>(0,d.Lk)("div",{id:"submission-site"},[(0,d.Lk)("h2",null,"Submission Site"),(0,d.Lk)("hr"),(0,d.Lk)("a",{href:"https://cmt3.research.microsoft.com/MedAGI2023",target:"_blank"},"https://cmt3.research.microsoft.com/MedAGI2023 ")],-1))),B=[z],F={key:1},P=t((()=>(0,d.Lk)("div",{id:"awards"},[(0,d.Lk)("h2",null,"Submission Site"),(0,d.Lk)("hr"),(0,d.Lk)("h2",null,"TBD")],-1))),G=[P];function W(a,e,i,t,o,v){return(0,d.uX)(),(0,d.CE)("div",s,[n,"2023"===v.currentYear?((0,d.uX)(),(0,d.CE)("div",l,r)):((0,d.uX)(),(0,d.CE)("div",c,u)),"2023"===v.currentYear?((0,d.uX)(),(0,d.CE)("div",f,h)):((0,d.uX)(),(0,d.CE)("div",p,k)),y,w,"2023"===v.currentYear?((0,d.uX)(),(0,d.CE)("div",L,A)):((0,d.uX)(),(0,d.CE)("div",I,T)),(0,d.Lk)("div",D,[S,E,M,(0,d.Lk)("div",null,[X,"2023"===v.currentYear?((0,d.uX)(),(0,d.CE)("div",Y,B)):((0,d.uX)(),(0,d.CE)("div",F,G))])])])}var J={computed:{currentYear(){return this.$route.params.year||(new Date).getFullYear().toString()}},methods:{fetchData(){this.currentYear}},created(){this.fetchData()}},_=i(1241);const j=(0,_.A)(J,[["render",W],["__scopeId","data-v-498df29e"]]);var x=j}}]);
//# sourceMappingURL=658.9e37c64b.js.map