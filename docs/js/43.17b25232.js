"use strict";(self["webpackChunkmiccai2023"]=self["webpackChunkmiccai2023"]||[]).push([[43],{1043:function(e,a,n){n.r(a),n.d(a,{default:function(){return B}});var i=n(3396),t=n(7139);const o=e=>((0,i.dD)("data-v-7ac06462"),e=e(),(0,i.Cn)(),e),l={id:"program"},s=o((()=>(0,i._)("div",{class:"main-title"},[(0,i._)("h1",null,"Program"),(0,i._)("div",{class:"main-title-deco"})],-1))),r={id:"oral"},d=o((()=>(0,i._)("h2",null,"Oral Sessions",-1))),m=o((()=>(0,i._)("hr",null,null,-1))),g={id:"oral-table",class:"table"},c=["rowspan"],u=o((()=>(0,i._)("br",null,null,-1))),p={class:"oral-content"},h=["rowspan"],P=o((()=>(0,i._)("br",null,null,-1))),f={class:"oral-content"},v={id:"oral-table-m",class:"table"},w=o((()=>(0,i._)("tr",{class:"sticky-header"},[(0,i._)("td",{class:"oral-time-m"},"Oral1 (8:50 - 9:40)")],-1))),M={class:"oral-content"},A=o((()=>(0,i._)("tr",{class:"sticky-header"},[(0,i._)("td",{class:"oral-time-m"},"Oral2 (11:10 - 12:10)")],-1))),S={class:"oral-content"},y={id:"poster"},C=o((()=>(0,i._)("h2",null,"Poster Sessions (9:40 - 10:30)",-1))),k=o((()=>(0,i._)("hr",null,null,-1))),D={class:"table"},_=o((()=>(0,i._)("tr",null,[(0,i._)("td",{colspan:"2",class:"poster-title sticky-header"},"Full-length Papers")],-1))),b={class:"poster-id"},I={class:"poster-name"},T={class:"table"},G=o((()=>(0,i._)("tr",null,[(0,i._)("td",{colspan:"2",class:"poster-title sticky-header"},"Extended Abstracts")],-1))),z={class:"oral-content"},E={class:"oral-content"};function F(e,a,n,o,F,L){return(0,i.wg)(),(0,i.iD)("div",l,[s,(0,i._)("div",r,[d,m,(0,i._)("table",g,[((0,i.wg)(!0),(0,i.iD)(i.HY,null,(0,i.Ko)(F.oral1,((e,a)=>((0,i.wg)(),(0,i.iD)("tr",{key:a},[0===a?((0,i.wg)(),(0,i.iD)("td",{key:0,rowspan:F.oral1.length,class:"oral-time"},[(0,i.Uk)("Oral 1"),u,(0,i.Uk)("(8:50 - 9:40)")],8,c)):(0,i.kq)("",!0),(0,i._)("td",p,(0,t.zw)(e["name"]),1)])))),128)),((0,i.wg)(!0),(0,i.iD)(i.HY,null,(0,i.Ko)(F.oral2,((e,a)=>((0,i.wg)(),(0,i.iD)("tr",{key:a},[0===a?((0,i.wg)(),(0,i.iD)("td",{key:0,rowspan:F.oral2.length,class:"oral-time"},[(0,i.Uk)("Oral 2"),P,(0,i.Uk)("(11:10 - 12:10)")],8,h)):(0,i.kq)("",!0),(0,i._)("td",f,(0,t.zw)(e["name"]),1)])))),128))]),(0,i._)("table",v,[w,((0,i.wg)(!0),(0,i.iD)(i.HY,null,(0,i.Ko)(F.oral1,((e,a)=>((0,i.wg)(),(0,i.iD)("tr",{key:a},[(0,i._)("td",M,(0,t.zw)(e["name"]),1)])))),128)),A,((0,i.wg)(!0),(0,i.iD)(i.HY,null,(0,i.Ko)(F.oral2,((e,a)=>((0,i.wg)(),(0,i.iD)("tr",{key:a},[(0,i._)("td",S,(0,t.zw)(e["name"]),1)])))),128))])]),(0,i._)("div",y,[C,k,(0,i._)("table",D,[_,((0,i.wg)(!0),(0,i.iD)(i.HY,null,(0,i.Ko)(F.paper,((e,a)=>((0,i.wg)(),(0,i.iD)("tr",{key:a},[(0,i._)("td",b,(0,t.zw)(e["id"]),1),(0,i._)("td",I,(0,t.zw)(e["name"]),1)])))),128))]),(0,i._)("table",T,[G,((0,i.wg)(!0),(0,i.iD)(i.HY,null,(0,i.Ko)(F.abstract,((e,a)=>((0,i.wg)(),(0,i.iD)("tr",{key:a},[(0,i._)("td",z,(0,t.zw)(e["id"]),1),(0,i._)("td",E,(0,t.zw)(e["name"]),1)])))),128))])])])}var L=JSON.parse('[{"sD":[{"name":"SAM-Path: A Segment Anything Model for Semantic Segmentation in Digital Pathology"},{"name":"GPC: Generative and general pathology image classifier"},{"name":"Transductive few-shot adapters for medical image segmentation"},{"name":"Cross-Task Attention Network: Improving Multi-Task Learning for Medical Imaging Applications"},{"name":"Input Augmentation with SAM: Boosting Medical Image Segmentation with Segmentation Foundation Model"},{"name":"Multi-Task Cooperative Learning via Searching for Flat Minima"}],"VO":[{"name":"MAP: Domain Generalization via Meta-Learning on Anatomy-Consistent Pseudo-Modalities"},{"name":"A General Computationally-Efficient 3D Reconstruction Pipeline for Multiple Images with Point Clouds"},{"name":"Concept Bottleneck with Visual Concept Filtering for Explainable Medical Image Classification"},{"name":"SAM Meets Robotic Surgery: An Empirical Study on Generalization, Robustness and Adaptation"},{"name":"Evaluation and improvement of Segment Anything Model for interactive histopathology image segmentation"}],"vD":[{"id":"P1","name":"SAM-Path: A Segment Anything Model for Semantic Segmentation in Digital Pathology"},{"id":"P2","name":"GPC: Generative and general pathology image classifier"},{"id":"P3","name":"Transductive few-shot adapters for medical image segmentation"},{"id":"P4","name":"Cross-Task Attention Network: Improving Multi-Task Learning for Medical Imaging Applications"},{"id":"P5","name":"Input Augmentation with SAM: Boosting Medical Image Segmentation with Segmentation Foundation Model"},{"id":"P6","name":"Multi-Task Cooperative Learning via Searching for Flat Minima"},{"id":"P7","name":"MAP: Domain Generalization via Meta-Learning on Anatomy-Consistent Pseudo-Modalities"},{"id":"P8","name":"A General Computationally-Efficient 3D Reconstruction Pipeline for Multiple Images with Point Clouds"},{"id":"P9","name":"Concept Bottleneck with Visual Concept Filtering for Explainable Medical Image Classification"},{"id":"P10","name":"SAM Meets Robotic Surgery: An Empirical Study on Generalization, Robustness and Adaptation"},{"id":"P11","name":"Evaluation and improvement of Segment Anything Model for interactive histopathology image segmentation"},{"id":"P12","name":"Empirical Analysis of a Segmentation Foundation Model in Prostate Imaging"},{"id":"P13","name":"CEmb-SAM: Segment Anything Model with Condition Embedding for Joint Learning from Heterogeneous Datasets"},{"id":"P14","name":"GPT4MIA: Utilizing Generative Pre-trained Transformer (GPT-3) as A Plug-and-Play Transductive Model for Medical Image Analysis"},{"id":"P15","name":"Task-driven prompt evolution for Foundation models"},{"id":"P16","name":"Generalizing Across Domains in Diabetic Retinopathy via Variational Autoencoders"},{"id":"P17","name":"Histopathological Image Analysis with Style-Augmented Feature Domain Mixing for Improved Generalization"}],"O3":[{"id":"P18","name":"Histopathology-Specific Foundation Model for Tissue Segmentation and Clustering"},{"id":"P19","name":"Multi Pose-based Convolutional Neural Network Model for Diagnosis of Patient with Central Lumbar Spinal Stenosis"},{"id":"P20","name":"Improving Intravenous Contrast Detection and Brain Filter Classification in Head CT Scans using a 3D CNN Model"},{"id":"P21","name":"Tyche: In-Context Learning for Stochastic Medical Image Segmentation"},{"id":"P22","name":"Diagnosis of Pigmented Skin Cancer with CBAM"},{"id":"P23","name":"Zero-shot Segmentation of Biomarkers in Optical Coherence Tomography Using Foundation Model Based on Bounding Box Prompting"},{"id":"P24","name":"Comparative Detection of Carpal Tunnel Syndrome in Muscle Ultrasound Images leveraging Heterogeneous Datasets"},{"id":"P25","name":"Extra-Surv: Extrapolated Transformer Networks for Survival Analysis"},{"id":"P26","name":"CLIP-IVP: CLIP-based Intraoral View Prediction Using Conditional GANs"},{"id":"P27","name":"Few-shot medical image classification with simple shape and texture text descriptors using vision-language models"},{"id":"P28","name":"Revisiting Active Learning in Histopathology Segmentation: Representativeness and Cost-Effective Active Learning"}]}]'),H={data(){return{oral1:L[0].sD,oral2:L[0].VO,paper:L[0].vD,abstract:L[0].O3}},methods:{}},O=n(89);const x=(0,O.Z)(H,[["render",F],["__scopeId","data-v-7ac06462"]]);var B=x}}]);
//# sourceMappingURL=43.17b25232.js.map