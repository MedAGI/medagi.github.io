"use strict";(self["webpackChunkmiccai2023"]=self["webpackChunkmiccai2023"]||[]).push([[875],{875:function(e,a,n){n.r(a),n.d(a,{default:function(){return z}});var i=n(3396),t=n(7139);const o=e=>((0,i.dD)("data-v-764733ba"),e=e(),(0,i.Cn)(),e),l={id:"program"},s=o((()=>(0,i._)("div",{class:"main-title"},[(0,i._)("h1",null,"Program"),(0,i._)("div",{class:"main-title-deco"})],-1))),r={id:"oral"},d=o((()=>(0,i._)("h2",null,"Oral Sessions",-1))),m=o((()=>(0,i._)("hr",null,null,-1))),g={id:"oral-table",class:"table"},c=["rowspan"],u=o((()=>(0,i._)("br",null,null,-1))),p={class:"oral-content"},P=["rowspan"],h=o((()=>(0,i._)("br",null,null,-1))),f={class:"oral-content"},v={id:"poster"},M=o((()=>(0,i._)("h2",null,"Poster Sessions (9:40 - 10:30)",-1))),w=o((()=>(0,i._)("hr",null,null,-1))),A={class:"table"},S=o((()=>(0,i._)("tr",null,[(0,i._)("td",{colspan:"2",class:"poster-title"},"Full-length Papers")],-1))),C={class:"poster-id"},y={class:"poster-name"},D={class:"table"},k=o((()=>(0,i._)("tr",null,[(0,i._)("td",{colspan:"2",class:"poster-title"},"Extended Abstracts")],-1))),b={class:"oral-content"},I={class:"oral-content"};function _(e,a,n,o,_,T){return(0,i.wg)(),(0,i.iD)("div",l,[s,(0,i._)("div",r,[d,m,(0,i._)("table",g,[((0,i.wg)(!0),(0,i.iD)(i.HY,null,(0,i.Ko)(_.oral1,((e,a)=>((0,i.wg)(),(0,i.iD)("tr",{key:a},[0===a?((0,i.wg)(),(0,i.iD)("td",{key:0,rowspan:_.oral1.length,class:"oral-time"},[(0,i.Uk)("Oral1"),u,(0,i.Uk)("(8:50 - 9:40)")],8,c)):(0,i.kq)("",!0),(0,i._)("td",p,(0,t.zw)(e["name"]),1)])))),128)),((0,i.wg)(!0),(0,i.iD)(i.HY,null,(0,i.Ko)(_.oral2,((e,a)=>((0,i.wg)(),(0,i.iD)("tr",{key:a},[0===a?((0,i.wg)(),(0,i.iD)("td",{key:0,rowspan:_.oral2.length,class:"oral-time"},[(0,i.Uk)("Oral 2"),h,(0,i.Uk)("(11:10 - 12:10)")],8,P)):(0,i.kq)("",!0),(0,i._)("td",f,(0,t.zw)(e["name"]),1)])))),128))])]),(0,i._)("div",v,[M,w,(0,i._)("table",A,[S,((0,i.wg)(!0),(0,i.iD)(i.HY,null,(0,i.Ko)(_.paper,((e,a)=>((0,i.wg)(),(0,i.iD)("tr",{key:a},[(0,i._)("td",C,(0,t.zw)(e["id"]),1),(0,i._)("td",y,(0,t.zw)(e["name"]),1)])))),128))]),(0,i._)("table",D,[k,((0,i.wg)(!0),(0,i.iD)(i.HY,null,(0,i.Ko)(_.abstract,((e,a)=>((0,i.wg)(),(0,i.iD)("tr",{key:a},[(0,i._)("td",b,(0,t.zw)(e["id"]),1),(0,i._)("td",I,(0,t.zw)(e["name"]),1)])))),128))])])])}var T=JSON.parse('[{"sD":[{"name":"SAM-Path: A Segment Anything Model for Semantic Segmentation in Digital Pathology"},{"name":"GPC: Generative and general pathology image classifier"},{"name":"Transductive few-shot adapters for medical image segmentation"},{"name":"Cross-Task Attention Network: Improving Multi-Task Learning for Medical Imaging Applications"},{"name":"Input Augmentation with SAM: Boosting Medical Image Segmentation with Segmentation Foundation Model"},{"name":"Multi-Task Cooperative Learning via Searching for Flat Minima"}],"VO":[{"name":"MAP: Domain Generalization via Meta-Learning on Anatomy-Consistent Pseudo-Modalities"},{"name":"A General Computationally-Efficient 3D Reconstruction Pipeline for Multiple Images with Point Clouds"},{"name":"Concept Bottleneck with Visual Concept Filtering for Explainable Medical Image Classification"},{"name":"SAM Meets Robotic Surgery: An Empirical Study on Generalization, Robustness and Adaptation"},{"name":"Evaluation and improvement of Segment Anything Model for interactive histopathology image segmentation"}],"vD":[{"id":"P1","name":"SAM-Path: A Segment Anything Model for Semantic Segmentation in Digital Pathology"},{"id":"P2","name":"GPC: Generative and general pathology image classifier"},{"id":"P3","name":"Transductive few-shot adapters for medical image segmentation"},{"id":"P4","name":"Cross-Task Attention Network: Improving Multi-Task Learning for Medical Imaging Applications"},{"id":"P5","name":"Input Augmentation with SAM: Boosting Medical Image Segmentation with Segmentation Foundation Model"},{"id":"P6","name":"Multi-Task Cooperative Learning via Searching for Flat Minima"},{"id":"P7","name":"MAP: Domain Generalization via Meta-Learning on Anatomy-Consistent Pseudo-Modalities"},{"id":"P8","name":"A General Computationally-Efficient 3D Reconstruction Pipeline for Multiple Images with Point Clouds"},{"id":"P9","name":"Concept Bottleneck with Visual Concept Filtering for Explainable Medical Image Classification"},{"id":"P10","name":"SAM Meets Robotic Surgery: An Empirical Study on Generalization, Robustness and Adaptation"},{"id":"P11","name":"Evaluation and improvement of Segment Anything Model for interactive histopathology image segmentation"},{"id":"P12","name":"Empirical Analysis of a Segmentation Foundation Model in Prostate Imaging"},{"id":"P13","name":"CEmb-SAM: Segment Anything Model with Condition Embedding for Joint Learning from Heterogeneous Datasets"},{"id":"P14","name":"GPT4MIA: Utilizing Generative Pre-trained Transformer (GPT-3) as A Plug-and-Play Transductive Model for Medical Image Analysis"},{"id":"P15","name":"Task-driven prompt evolution for Foundation models"},{"id":"P16","name":"Generalizing Across Domains in Diabetic Retinopathy via Variational Autoencoders"},{"id":"P17","name":"Histopathological Image Analysis with Style-Augmented Feature Domain Mixing for Improved Generalization"}],"O3":[{"id":"P18","name":"Histopathology-Specific Foundation Model for Tissue Segmentation and Clustering"},{"id":"P19","name":"Multi Pose-based Convolutional Neural Network Model for Diagnosis of Patient with Central Lumbar Spinal Stenosis"},{"id":"P20","name":"Improving Intravenous Contrast Detection and Brain Filter Classification in Head CT Scans using a 3D CNN Model"},{"id":"P21","name":"Tyche: In-Context Learning for Stochastic Medical Image Segmentation"},{"id":"P22","name":"Diagnosis of Pigmented Skin Cancer with CBAM"},{"id":"P23","name":"Zero-shot Segmentation of Biomarkers in Optical Coherence Tomography Using Foundation Model Based on Bounding Box Prompting"},{"id":"P24","name":"Comparative Detection of Carpal Tunnel Syndrome in Muscle Ultrasound Images leveraging Heterogeneous Datasets"},{"id":"P25","name":"Extra-Surv: Extrapolated Transformer Networks for Survival Analysis"},{"id":"P26","name":"CLIP-IVP: CLIP-based Intraoral View Prediction Using Conditional GANs"},{"id":"P27","name":"Few-shot medical image classification with simple shape and texture text descriptors using vision-language models"},{"id":"P28","name":"Revisiting Active Learning in Histopathology Segmentation: Representativeness and Cost-Effective Active Learning"}]}]'),G={data(){return{oral1:T[0].sD,oral2:T[0].VO,paper:T[0].vD,abstract:T[0].O3}},methods:{}},E=n(89);const F=(0,E.Z)(G,[["render",_],["__scopeId","data-v-764733ba"]]);var z=F}}]);
//# sourceMappingURL=875.96a47250.js.map